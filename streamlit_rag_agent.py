import json
import traceback
import uuid
from pathlib import Path

import dotenv
import streamlit as st

# åŠ è½½ç¯å¢ƒå˜é‡
dotenv.load_dotenv()

from agent.graph import get_graph
from retriever.vectorize_files import vectorize_uploaded_files


def get_message_type(message) -> str:
    """è·å– LangChain æ¶ˆæ¯ç±»å‹åç§°"""
    # æ£€æŸ¥ type å±æ€§ä¼˜å…ˆï¼ˆLangGraph æ ‡å‡†ï¼‰
    msg_type = getattr(message, 'type', None)
    if msg_type:
        type_map = {
            'human': 'HumanMessage',
            'ai': 'AIMessage',
            'tool': 'ToolMessage'
        }
        return type_map.get(msg_type, f'{msg_type.capitalize()}Message')

    # å¤‡ç”¨ï¼šæ£€æŸ¥ role å±æ€§
    role = getattr(message, 'role', None)
    if role:
        role_map = {
            'user': 'HumanMessage',
            'assistant': 'AIMessage',
            'tool': 'ToolMessage'
        }
        return role_map.get(role, f'{role.capitalize()}Message')

    return 'UnknownMessage'


# é¡µé¢é…ç½®
st.set_page_config(
    page_title="RAG Agent è°ƒè¯•å™¨",
    page_icon="ğŸ¤–",
    layout="wide"
)


def main():
    st.markdown('### ğŸ¤– RAG Agent è°ƒè¯•å™¨')

    # ä½¿ç”¨ä¾§è¾¹æ æ·»åŠ çŸ¥è¯†åº“ç®¡ç†åŠŸèƒ½
    with st.sidebar:
        st.header("âš™ï¸ é…ç½®")

        # ç”¨æˆ·IDè¾“å…¥
        user_id = st.text_input("ç”¨æˆ·ID", value="1", help="ç”¨äºè®°å¿†ç®¡ç†ï¼Œä¸åŒç”¨æˆ·IDçš„è®°å¿†æ˜¯éš”ç¦»çš„")

        st.header("ğŸ“š çŸ¥è¯†åº“ç®¡ç†")

        # åˆ›å»ºçŸ¥è¯†åº“ç›®å½•
        knowledge_db_path = Path("data_base/knowledge_db/data")
        knowledge_db_path.mkdir(parents=True, exist_ok=True)

        # æ–‡ä»¶ä¸Šä¼ 
        uploaded_file = st.file_uploader(
            "ä¸Šä¼ çŸ¥è¯†åº“æ–‡ä»¶",
            type=['pdf', 'docx', 'txt', 'md', 'csv'],
            accept_multiple_files=False,
            help="æ”¯æŒ PDF, DOCX, TXT, MD, CSV æ ¼å¼ï¼Œå•ä¸ªæ–‡ä»¶ä¸è¶…è¿‡ 5MB"
        )

        if uploaded_file is not None:
            # æ£€æŸ¥æ–‡ä»¶å¤§å°
            if uploaded_file.size > 5 * 1024 * 1024:  # 5MB
                st.error("æ–‡ä»¶å¤§å°è¶…è¿‡ 5MB é™åˆ¶")
            else:
                # ä¿å­˜ä¸Šä¼ çš„æ–‡ä»¶
                file_path = knowledge_db_path / uploaded_file.name

                with open(file_path, "wb") as f:
                    f.write(uploaded_file.getvalue())

                st.success(f"æ–‡ä»¶å·²ä¿å­˜: {uploaded_file.name}")

                # å‘é‡åŒ–æŒ‰é’®
                if st.button("ğŸ”¬ å‘é‡åŒ–"):
                    try:
                        with st.spinner("æ­£åœ¨å‘é‡åŒ–æ–‡ä»¶..."):
                            success = vectorize_uploaded_files([str(file_path)])
                            if success:
                                st.success("å‘é‡åŒ–å®Œæˆï¼")
                            else:
                                st.error("å‘é‡åŒ–å¤±è´¥")
                    except Exception as e:
                        st.error(f"å‘é‡åŒ–è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {str(e)}")
                        print(traceback.format_exc())

        st.header("ğŸ—‘ï¸ æ“ä½œ")

        # æ¸…é™¤å¯¹è¯æŒ‰é’®
        if st.button("æ¸…é™¤å¯¹è¯"):
            st.session_state.messages = []
            st.session_state.debug_info = []
            st.session_state.thread_id = str(uuid.uuid4())
            st.success("å¯¹è¯å·²æ¸…é™¤")

    # åˆå§‹åŒ– session state
    if "messages" not in st.session_state:
        st.session_state.messages = []
    if "debug_info" not in st.session_state:
        st.session_state.debug_info = []
    if "thread_id" not in st.session_state:
        st.session_state.thread_id = str(uuid.uuid4())

    # åˆå§‹åŒ– graph
    if "graph" not in st.session_state:
        with st.spinner("æ­£åœ¨åˆå§‹åŒ–æ™ºèƒ½ä½“..."):
            st.session_state.graph = get_graph()

    # åˆ›å»ºä¸¤åˆ—å¸ƒå±€ï¼šå·¦ä¾§èŠå¤©ï¼Œå³ä¾§è°ƒè¯•ä¿¡æ¯
    col1, col2 = st.columns([2, 1])

    with col1:
        st.subheader("ğŸ’¬ å¯¹è¯")

        # èŠå¤©å®¹å™¨
        messages = st.container(height=600)

        # æ˜¾ç¤ºå¯¹è¯å†å²
        for message in st.session_state.messages:
            with messages.chat_message(message["role"]):
                st.write(message["content"])

        # èŠå¤©è¾“å…¥
        if prompt := st.chat_input("è¾“å…¥æ‚¨çš„é—®é¢˜..."):
            # å°†ç”¨æˆ·æ¶ˆæ¯æ·»åŠ åˆ°å¯¹è¯å†å²
            st.session_state.messages.append({"role": "user", "content": prompt})

            with messages.chat_message("user"):
                st.write(prompt)

            # æ¸…ç©ºè°ƒè¯•ä¿¡æ¯
            st.session_state.debug_info = []

            # é…ç½®
            config = {
                "configurable": {
                    "thread_id": st.session_state.thread_id,
                    "user_id": user_id
                }
            }

            # ä½¿ç”¨ graph.stream() è·å–æ‰§è¡Œæµ
            ai_answer = ""
            assistant_messages = []

            with st.spinner("æ™ºèƒ½ä½“æ­£åœ¨æ€è€ƒ..."):
                for chunk in st.session_state.graph.stream(
                        {
                            "messages": [
                                {
                                    "role": "user",
                                    "content": prompt,
                                }
                            ]
                        },
                        config,
                        stream_mode="values",
                ):
                    if "messages" in chunk:
                        last_message = chunk["messages"][-1]
                        # æ”¶é›†æ‰€æœ‰çš„assistantæ¶ˆæ¯
                        message_type = get_message_type(last_message)
                        if message_type == "AIMessage":
                            assistant_messages.append({
                                "content": last_message.content,
                                "tool_calls": getattr(last_message, 'tool_calls', None)
                            })

                        # æ·»åŠ è¯¦ç»†çš„è°ƒè¯•ä¿¡æ¯
                        st.session_state.debug_info.append({
                            "type": "message",
                            "message_type": get_message_type(last_message),
                            "role": getattr(last_message, 'role', 'unknown'),
                            "content": str(last_message),
                            "tool_calls": getattr(last_message, 'tool_calls', None)
                        })
                    elif "__interrupt__" in chunk:
                        action = chunk["__interrupt__"][0]
                        debug_text = "INTERRUPTED:\n" + json.dumps(action.value, indent=2, ensure_ascii=False)
                        st.session_state.debug_info.append({
                            "type": "interrupt",
                            "content": debug_text
                        })

            # ä½¿ç”¨æœ€åä¸€æ¡æ²¡æœ‰ tool_calls çš„ AI æ¶ˆæ¯ä½œä¸ºæœ€ç»ˆå›ç­”
            final_answer = ""
            for msg in reversed(assistant_messages):
                # ä»…é€‰æ‹©æ²¡æœ‰ tool_calls çš„æ¶ˆæ¯ä½œä¸ºæœ€ç»ˆå›ç­”
                if not msg.get('tool_calls'):
                    if msg.get('content') and msg['content'].strip():
                        final_answer = msg['content']
                        break

            # æ˜¾ç¤º AI å›ç­”
            if final_answer:
                st.session_state.messages.append({"role": "assistant", "content": final_answer})
                with messages.chat_message("assistant"):
                    st.markdown(final_answer)  # ä½¿ç”¨markdownæ ¼å¼åŒ–æ˜¾ç¤º

            # è§¦å‘å³ä¾§è°ƒè¯•ä¿¡æ¯æ›´æ–°
            st.rerun()

    with col2:
        st.subheader("ğŸ” è°ƒè¯•ä¿¡æ¯")

        # æ˜¾ç¤ºè°ƒè¯•ä¿¡æ¯
        if st.session_state.debug_info:
            with st.container(height=600):
                for i, debug in enumerate(st.session_state.debug_info):
                    if debug["type"] == "message":
                        # æ ¹æ®æ¶ˆæ¯ç±»å‹æ˜¾ç¤ºä¸åŒçš„å›¾æ ‡å’Œæ ‡é¢˜
                        message_type = debug.get("message_type", "UnknownMessage")

                        type_icon = {
                            "HumanMessage": "ğŸ‘¤",
                            "AIMessage": "ğŸ¤–",
                            "ToolMessage": "ğŸ”§"
                        }.get(message_type, "ğŸ“")

                        # æ„å»ºæ ‡é¢˜ï¼ŒåŒ…å«å·¥å…·è°ƒç”¨ä¿¡æ¯
                        title = f"{type_icon} {message_type}"

                        # å¯¹äºæœ‰ tool_calls çš„ AIMessageï¼Œæ·»åŠ å·¥å…·è°ƒç”¨å‰ç¼€
                        if message_type == "AIMessage" and debug.get("tool_calls"):
                            tool_names = [call.get("name", "unknown") for call in debug["tool_calls"]]
                            tool_str = ", ".join(tool_names[:2])  # æœ€å¤šæ˜¾ç¤º 2 ä¸ªå·¥å…·åç§°
                            if len(tool_names) > 2:
                                tool_str += f" ç­‰{len(tool_names)}ä¸ª"
                            title = f"{type_icon} AIMessage (å·¥å…·è°ƒç”¨: {tool_str})"

                        # å¯¹äº ToolMessageï¼Œå°è¯•è·å–å·¥å…·åç§°
                        if message_type == "ToolMessage":
                            # ToolMessage é€šå¸¸æœ‰ name å±æ€§æˆ– content åŒ…å«å·¥å…·å
                            tool_name = getattr(debug, 'name', None)
                            if tool_name:
                                title = f"{type_icon} ToolMessage ({tool_name})"

                        title += f" {i+1}"

                        # åˆ¤æ–­æ˜¯å¦ä¸ºæœ€ç»ˆ AI å›å¤ï¼ˆæ²¡æœ‰ tool_calls ä¸”æœ‰å†…å®¹ï¼‰
                        is_final = bool(message_type == "AIMessage" and
                                       not debug.get("tool_calls") and
                                       debug.get("content", "").strip())

                        with st.expander(title, expanded=is_final):
                            # æ˜¾ç¤ºå·¥å…·è°ƒç”¨ä¿¡æ¯
                            if debug.get("tool_calls"):
                                st.write("**å·¥å…·è°ƒç”¨:**")
                                for call in debug["tool_calls"]:
                                    st.code(json.dumps({
                                        "name": call.get("name"),
                                        "args": call.get("args", {})
                                    }, indent=2, ensure_ascii=False), language="json")
                            # æ˜¾ç¤ºæ¶ˆæ¯å†…å®¹
                            if debug.get("content"):
                                st.write("**å†…å®¹:**")
                                st.text(debug["content"])
                    elif debug["type"] == "interrupt":
                        with st.expander(f"â¸ï¸ ä¸­æ–­ {i+1}", expanded=True):
                            st.text(debug["content"])
        else:
            st.info("æš‚æ— è°ƒè¯•ä¿¡æ¯ï¼Œå¼€å§‹å¯¹è¯åæ˜¾ç¤º")

        # æ˜¾ç¤ºä¼šè¯ä¿¡æ¯
        st.divider()
        st.text("ä¼šè¯ä¿¡æ¯:")
        st.text(f"ç”¨æˆ·ID: {user_id}")
        st.text(f"çº¿ç¨‹ID: {st.session_state.thread_id}")
        st.text(f"æ¶ˆæ¯æ•°: {len(st.session_state.messages)}")


if __name__ == "__main__":
    main()